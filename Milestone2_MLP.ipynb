{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Milestone2_MLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeLaKo/apple-tree-disease/blob/main/Milestone2_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the data directly through Kaggle's API"
      ],
      "metadata": {
        "id": "TqzOGBFWtYKn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NF6qQ5qUmQI_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79165f43-99c1-4b92-8c32-466ac19fea75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q kaggle==1.5.8"
      ],
      "metadata": {
        "id": "ciuScTfXr0VL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/MLP/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lm1ktmfxsmpm",
        "outputId": "3bbe710b-684f-4205-d20f-b51c8bfa60b7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/MLP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "O-H80pCbsuzS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/MLP/\"\n",
        "! kaggle competitions download -c plant-pathology-2021-fgvc8"
      ],
      "metadata": {
        "id": "XIrQYT90uv5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39c5c591-ba86-4ccd-a9a6-f7e605b0c69b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading plant-pathology-2021-fgvc8.zip to /content/gdrive/MyDrive/MLP\n",
            "  7% 1.11G/14.9G [00:10<02:07, 116MB/s]\n",
            "User cancelled operation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip -q plant-pathology-2021-fgvc8.zip -d train"
      ],
      "metadata": {
        "id": "4w4s3qRQ3Z6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data processing\n"
      ],
      "metadata": {
        "id": "v192m162tVHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "%cd /content/gdrive/MyDrive/MLP/train/"
      ],
      "metadata": {
        "id": "ibOekLk5tlko",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6c764d0-251b-4b18-b767-35f4e3661309"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/MLP/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import mlxtend package for confusion matrix\n",
        "import mlxtend\n",
        "                                                          \n",
        "print(mlxtend.__version__) \n",
        "\n",
        "! pip install mlxtend --upgrade --no-deps\n",
        "\n",
        "print(mlxtend.__version__) \n",
        "\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dHkG28jM9N9",
        "outputId": "3d920dd0-b563-474f-9062-b20b565210a6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.19.0\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.7/dist-packages (0.19.0)\n",
            "0.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('train.csv')\n",
        "#print(df.head())\n",
        "\n",
        "# df_test = pd.read_csv('sample_submission.csv')\n",
        "# print(df_test.head())"
      ],
      "metadata": {
        "id": "4oGL6rPetoLs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_labels = df['labels'].to_list()\n",
        "\n",
        "for i in range(len(new_labels)):\n",
        "  if new_labels[i] == 'scab frog_eye_leaf_spot complex' or new_labels[i] == 'scab frog_eye_leaf_spot':\n",
        "    new_labels[i] = 'scab'\n",
        "  elif new_labels[i] == 'frog_eye_leaf_spot complex':\n",
        "    new_labels[i] = 'frog_eye_leaf_spot'\n",
        "  elif new_labels[i] == 'powdery_mildew complex':\n",
        "    new_labels[i] = 'powdery_mildew'\n",
        "  elif new_labels[i] == 'rust complex' or new_labels[i] == 'rust frog_eye_leaf_spot':\n",
        "    new_labels[i] = 'rust'\n"
      ],
      "metadata": {
        "id": "MKIFbUN5mLzA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['adjusted labels'] = np.array(new_labels)\n",
        "df = df.drop('labels', axis = 1)\n",
        "\n",
        "#print(df)"
      ],
      "metadata": {
        "id": "vHb0J7dOqTMM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(df, sample_size):\n",
        "  \"\"\"\n",
        "  This function gets an equal sample inclusive of all classes from the input dataframe\n",
        "  \"\"\"\n",
        "  df_sampled = []\n",
        "  classes = df['adjusted labels'].unique()\n",
        "\n",
        "  for i in classes:\n",
        "      g = df[df['adjusted labels'] == i].sample(sample_size)\n",
        "      df_sampled.append(g)\n",
        "\n",
        "  df_sampled = pd.concat(df_sampled)\n",
        "  return df_sampled\n",
        "\n",
        "df_sampled = sample(df, 1184)\n",
        "print(df_sampled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zh7Rr6dNzlMN",
        "outputId": "529f8fb9-c07a-4e13-bfcf-bbcadaa1ae95"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      image adjusted labels\n",
            "10481  c89a4c8d729b945f.jpg         healthy\n",
            "5463   a9bfd73e09b00cc1.jpg         healthy\n",
            "16778  f56ad0b4ab965a82.jpg         healthy\n",
            "17869  fc803b33128edee8.jpg         healthy\n",
            "1383   8a966626bbb96c94.jpg         healthy\n",
            "...                     ...             ...\n",
            "7019   b23434724e9bd4cb.jpg  powdery_mildew\n",
            "8481   bcd28d8f242f3730.jpg  powdery_mildew\n",
            "3406   9b9832ecbd60702f.jpg  powdery_mildew\n",
            "17746  fbc483ae483edc90.jpg  powdery_mildew\n",
            "13636  e00f934d9e50ad5b.jpg  powdery_mildew\n",
            "\n",
            "[7104 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(df):\n",
        "  \"\"\"\n",
        "  This function returns all classes and combination of classes found in the input-dataframe, and returns\n",
        "  the one-hot encoded version\n",
        "  \"\"\"\n",
        "  one_hot = pd.get_dummies(df['adjusted labels'])\n",
        "  df = df.drop('adjusted labels', axis = 1)\n",
        "  df = df.join(one_hot)\n",
        "  return df\n",
        "\n",
        "df_onehot = one_hot(df_sampled)\n",
        "#print(df_onehot)\n",
        "\n",
        "# df_test = one_hot(df_test)\n",
        "# print(df_test.head())"
      ],
      "metadata": {
        "id": "GdWniTfft-GO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import layers, models, preprocessing\n",
        "\n",
        "def train_and_evaluate(model, train_x, train_y, val_x, val_y, preprocess={}, epochs=20, augment={}):\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    train_gen = preprocessing.image.ImageDataGenerator(**preprocess, **augment)\n",
        "    train_gen.fit(train_x) \n",
        "\n",
        "    val_gen = preprocessing.image.ImageDataGenerator(**preprocess)\n",
        "    val_gen.fit(train_x)\n",
        "\n",
        "    history = model.fit(train_gen.flow(train_x, train_y), epochs=epochs, \n",
        "                        validation_data=val_gen.flow(val_x, val_y))\n",
        "\n",
        "    fig, axs = plt.subplots(1,2,figsize=(20,5)) \n",
        "\n",
        "    for i, metric in enumerate(['loss', 'accuracy']):\n",
        "        axs[i].plot(history.history[metric])\n",
        "        axs[i].plot(history.history['val_'+metric])\n",
        "        axs[i].legend(['training', 'validation'], loc='best')\n",
        "\n",
        "        axs[i].set_title('Model '+metric)\n",
        "        axs[i].set_ylabel(metric)\n",
        "        axs[i].set_xlabel('epoch')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Validation Accuracy: {model.evaluate(val_gen.flow(val_x, val_y))[1]}\")"
      ],
      "metadata": {
        "id": "2uvdJ8Yh3W7g"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert dictionary into a hashable type\n",
        "df_dict = df_onehot.set_index('image').T.to_dict('list')\n",
        "\n",
        "# gather names of all images in the image-directory\n",
        "train_images = os.listdir('train_images/')\n",
        "\n",
        "# # empty column for the actual images\n",
        "# df_onehot[\"image_pixels\"] = 0\n",
        "\n",
        "images = []\n",
        "# find corresponding key to image from directory, and add that image to a list\n",
        "for image in df_dict.keys():\n",
        "  if image in train_images:\n",
        "    img = cv2.imread('train_images/' + image)\n",
        "    img = cv2.resize(img, (96, 96)) \n",
        "    images.append(img)\n",
        "\n",
        "labels = list(df_dict.values())"
      ],
      "metadata": {
        "id": "4jts4lwY0YS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = np.array(images)\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "o4A7xjIFAwyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(images, labels, test_size = 0.3, random_state=42)"
      ],
      "metadata": {
        "id": "_LAtB1dQnt0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define Sequential model\n",
        "model = models.Sequential()\n",
        "\n",
        "# create convolutional layer and max pooling layer\n",
        "\n",
        "model.add(layers.Conv2D(32, (3, 3), activation=tf.keras.layers.LeakyReLU(alpha=0.5), padding='same', input_shape=(96, 96, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# create convolutional layer (larger) and max pooling layer\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation=tf.keras.layers.LeakyReLU(alpha=0.5), padding='same'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "# flatten layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(layers.Dense(256, activation=tf.keras.layers.LeakyReLU(alpha=0.5)))\n",
        "\n",
        "# apply softmax activation for final layer classification\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(layers.Dense(6, activation='softmax'))\n",
        "\n",
        "# normalize input data: set preprocesing dictionary\n",
        "preprocess = {'featurewise_center': True, 'featurewise_std_normalization' : True}\n",
        "\n",
        "# run training and evaluation function\n",
        "train_and_evaluate(model, x_train, y_train, x_val, y_val, preprocess)"
      ],
      "metadata": {
        "id": "ULlZim8l2zKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "aEjUnYrJ6u2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import math as tfmath\n",
        "\n",
        "classes = df['adjusted labels'].unique()\n",
        "display(classes)\n",
        "#x_test_flat = x_train.reshape(x_val.shape[0], (96, 96, 3)) # image_size\n",
        "\n",
        "y_true = tf.argmax(y_val, axis=1)\n",
        "y_pred = tf.argmax(model(x_val), axis=1)\n",
        "\n",
        "conf_matrix = tfmath.confusion_matrix(y_true, y_pred, num_classes=6)\n",
        "\n",
        "ax = sns.heatmap(conf_matrix, xticklabels=classes, yticklabels=classes)\n",
        "ax.set(xlabel='Predicted Class', ylabel='Actual Class')\n",
        "plt.show()\n",
        "\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "id": "jcwt60b_Jtc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install mlxtend"
      ],
      "metadata": {
        "id": "DMDHNCSmzZ2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define data for in confusion matrix\n",
        "y_true = tf.argmax(y_val, axis=1)\n",
        "y_pred = tf.argmax(model(x_val), axis=1)\n",
        "\n",
        "# set labels for confusion matrix\n",
        "labels =  df['adjusted labels'].unique()\n",
        "display(labels)\n",
        "# create and plot matrix\n",
        "mtrx = confusion_matrix(y_true, y_pred)\n",
        "plot_confusion_matrix(conf_mat = mtrx, figsize=(8, 8), class_names=labels, colorbar=True, show_normed = True) # class_names=labels,"
      ],
      "metadata": {
        "id": "wRrn2C6vNU6q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}